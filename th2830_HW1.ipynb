{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import statsmodels.api as sm\n",
    "from scipy.optimize import minimize\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_data = pd.read_csv(\"./winequality-red.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wine_data.iloc[:,0:-1].values\n",
    "y = wine_data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Regression equations and functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I choose to ignore the intercept for this homework. So the equation for the linear model to predict y from X is:  $$y = \\Sigma_{i=1}^{9} \\beta_{i}x_i = X\\beta$$\n",
    "And the equation for computing RSS is: \n",
    "$$RSS(\\beta) = \\Sigma_{i=1}^{m}(y_i - X_{i}\\beta)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(X, beta):\n",
    "    \"\"\"\n",
    "    X: feature matrix\n",
    "    beta: parameter vector\n",
    "    return: predicting vector for y\n",
    "    \"\"\"\n",
    "    return np.dot(X,beta)\n",
    "\n",
    "def RSS(beta,X,y):\n",
    "    \"\"\"\n",
    "    beta: parameter vector\n",
    "    X: feature matrix\n",
    "    y: y for testing\n",
    "    return: RSS\n",
    "    \"\"\"\n",
    "    y_pred = pred(X,beta)\n",
    "    return sum((y_pred-y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Optimizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta0 = np.random.normal(0,1,X_train.shape[1])\n",
    "res = minimize(fun=RSS, x0=beta0, args=(X_train,y_train))\n",
    "beta_hat = res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the qualitative results from your model? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** The qualitative results from my model is shown below. Some features have posive impact on quality while some features have negative impact on quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed acidity: 0.048\n",
      "volatile acidity: -1.118\n",
      "citric acid: -0.276\n",
      "residual sugar: 0.020\n",
      "chlorides: -1.769\n",
      "free sulfur dioxide: 0.005\n",
      "total sulfur dioxide: -0.003\n",
      "density: -36.691\n",
      "pH: -0.348\n",
      "sulphates: 0.930\n",
      "alcohol: 0.266\n"
     ]
    }
   ],
   "source": [
    "feature_name = wine_data.columns[:-1]\n",
    "for i,j in zip(feature_name, beta_hat[1:]):\n",
    "    print(\"{}: {:.3f}\".format(i,j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which features seem to be most important?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** If we do not consider normalizatin process and simply read the coefficients of the features learned by this linear model, density is the most important feature since it has max absolute value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you think that the magnitude of the features in X may affect the results (for example, the average total sulfur dioxide across all wines is 46.47, but the average chlorides is only 0.087)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** Yes, the magnitude of the features in X may affect the results. If we do normalization, the coefficents of the features may be different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well does your model fit? You should be able to measure the goodness of fit, RSS, on both the training data and the test data, but only report the results on the test data. In Machine Learning we almost always only care about how well the model fits on data that has not been used to fit the model, because we need to use the model in the future, not the past. Therefore, we only report performance with holdout data, or test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** From the following result we can see that RSS on testing set is 122.58."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS on training set is:  544.8211250922011\n",
      "RSS on testing set is:  122.58238171946738\n",
      "MSE on training set is:  0.4259742963973425\n",
      "MSE on testing set is:  0.38306994287333557\n"
     ]
    }
   ],
   "source": [
    "RSS_test = RSS(beta_hat,X_test,y_test)\n",
    "RSS_train = RSS(beta_hat,X_train,y_train)\n",
    "print(\"RSS on training set is: \", RSS_train)\n",
    "print(\"RSS on testing set is: \", RSS_test)\n",
    "print(\"MSE on training set is: \", RSS_train/X_train.shape[0])\n",
    "print(\"MSE on testing set is: \", RSS_test/X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the end result or RSS change if you try different initial values of β? What happens if you change the magnitude of the initial β?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** I choose to change the magnitude of the initial $\\beta$ and the result is showen below. From results we can know that change the magnitude of the initial $\\beta$ will not change the final RSS, since linear regression is looking for the global optima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS of initial beta with mean 0:  122.58394737125313\n",
      "RSS of initial beta with mean 1:  122.58278478892431\n",
      "RSS of initial beta with mean 5:  122.58298928450189\n",
      "RSS of initial beta with mean 10:  122.58330601805694\n"
     ]
    }
   ],
   "source": [
    "beta_dic = {}\n",
    "for i in [0,1,5,10]:\n",
    "    beta0 = np.random.normal(5,1,X_train.shape[1])\n",
    "    res = minimize(fun=RSS, x0=beta0, args=(X_train,y_train))\n",
    "    beta_hat = res.x\n",
    "    print(\"RSS of initial beta with mean {}: \".format(i), RSS(beta_hat,X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the choice of solver method change the end result or RSS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** I tried some solver methods below. They almost generated the same RSS except for the Nelder-Mead method. The Nelder–Mead technique is a heuristic search method that can converge to non-stationary points, so it may not find the global optima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method:  Nelder-Mead :   202.38190261977604\n",
      "method:  Powell :   124.09855585876436\n",
      "method:  CG :   121.51907876858523\n",
      "method:  BFGS :   122.58286221147135\n",
      "method:  SLSQP :   122.582934878148\n",
      "method:  L-BFGS-B :   121.51825765503396\n"
     ]
    }
   ],
   "source": [
    "methods = ['Nelder-Mead','Powell','CG','BFGS','SLSQP','L-BFGS-B']\n",
    "beta0 = np.random.normal(0,1,X_train.shape[1])\n",
    "for method in methods:\n",
    "    res = minimize(fun=RSS, x0=beta0, method=method, args=(X_train,y_train))\n",
    "    beta_hat = res.x\n",
    "    print(\"method: \", method, \":  \", RSS(beta_hat,X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Regularizing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try adding in an L2 (aka Ridge) regularization penalty to your model above to create a new, regularized model. See equation 3.41 for guidance. You will need to choose a value of lambda, so start with something small, like 0.01. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** As shown below, RSS with L2 regularization is 121.62."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS with L2 regularization:  121.62383944668497\n"
     ]
    }
   ],
   "source": [
    "def Ridge(beta,X,y):\n",
    "    \"\"\"\n",
    "    beta: parameter vector\n",
    "    X: feature matrix\n",
    "    y: y for testing\n",
    "    return: RSS\n",
    "    \"\"\"\n",
    "    y_pred = pred(X,beta)\n",
    "    return sum((y_pred-y)**2) + lamda*sum((beta[1:]**2))\n",
    "\n",
    "beta0 = np.random.normal(0,1,X_train.shape[1])\n",
    "lamda = 0.01\n",
    "res = minimize(fun=Ridge, x0=beta0, args=(X_train,y_train))\n",
    "beta_hat = res.x\n",
    "print(\"RSS with L2 regularization: \",RSS(beta_hat,X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does RSS on the training data change? How does RSS on the test data change?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** From the result shown below, RSS on training data changed from 544.82 to 545.65, became a little bit higher while RSS on testing data changed from 121.58 to 121.62, bacame a litter bit lower, but not very significant. I will try to use normalization in Question 5 to see whether things can become better if normalization is conducted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta0 = np.random.normal(0,1,X_train.shape[1])\n",
    "lamda = 0.01\n",
    "beta_hat_without_L2 = minimize(fun=RSS, x0=beta0, args=(X_train,y_train)).x\n",
    "beta_hat_with_L2 = minimize(fun=Ridge, x0=beta0, args=(X_train,y_train)).x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS without L2 regularization on training set:  544.8211248988536\n",
      "RSS with L2 regularization on training set:  545.6587836021948\n",
      "RSS without L2 regularization on test set:  122.58333984739846\n",
      "RSS with L2 regularization on test set:  121.62387477457708\n"
     ]
    }
   ],
   "source": [
    "print(\"RSS without L2 regularization on training set: \",RSS(beta_hat_without_L2,X_train,y_train))\n",
    "print(\"RSS with L2 regularization on training set: \",RSS(beta_hat_with_L2,X_train,y_train))\n",
    "print(\"RSS without L2 regularization on test set: \",RSS(beta_hat_without_L2,X_test,y_test))\n",
    "print(\"RSS with L2 regularization on test set: \",RSS(beta_hat_with_L2,X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try using an L1 (aka Lasso) regularization penalty instead. See equation 3.51 for example. Report your findings on how RSS changes, and if you can roughly tune lambda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** First keep lambda as 0.01, RSS on testing data changed from 122.58 to 122.35, bacame a litter bit lower, but not very significant. Then I will try to tune lambda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS without L1 regularization on training set:  544.8211248988536\n",
      "RSS with L1 regularization on training set:  544.855795886887\n",
      "RSS without L1 regularization on test set:  122.58333984739846\n",
      "RSS with L1 regularization on test set:  122.35133901052352\n"
     ]
    }
   ],
   "source": [
    "def Lasso(beta,X,y):\n",
    "    \"\"\"\n",
    "    beta: parameter vector\n",
    "    X: feature matrix\n",
    "    y: y for testing\n",
    "    return: RSS\n",
    "    \"\"\"\n",
    "    y_pred = pred(X,beta)\n",
    "    return sum((y_pred-y)**2) + lamda*sum(abs(beta[1:]))\n",
    "# First use lambda as 0.01\n",
    "beta0 = np.random.normal(0,1,X_train.shape[1])\n",
    "lamda = 0.01\n",
    "beta_hat_with_L1 = minimize(fun=Lasso, x0=beta0, args=(X_train,y_train)).x\n",
    "print(\"RSS without L1 regularization on training set: \",RSS(beta_hat_without_L2,X_train,y_train))\n",
    "print(\"RSS with L1 regularization on training set: \",RSS(beta_hat_with_L1,X_train,y_train))\n",
    "print(\"RSS without L1 regularization on test set: \",RSS(beta_hat_without_L2,X_test,y_test))\n",
    "print(\"RSS with L1 regularization on test set: \",RSS(beta_hat_with_L1,X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first tried lambda from 0 to 100, and found that RSS reach minima when lambda lies between 0.001 and 0.1. Then I grid search lambda from 0.001 to 0.1. The result plot is shown below. The best lambda for this problem is around 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 122.58292639006923\n",
      "1e-06 122.58302331980934\n",
      "1e-05 122.58194673783503\n",
      "0.0001 122.58144445761165\n",
      "0.001 122.55850186682224\n",
      "0.01 122.35133901052352\n",
      "0.1 121.55892881264457\n",
      "1 121.49148767901363\n",
      "10 122.96264626940136\n",
      "100 141.07397210859327\n"
     ]
    }
   ],
   "source": [
    "lamda_lst = [0,0.000001,0.00001,0.0001,0.001,0.01,0.1,1,10,100]\n",
    "for lamda in lamda_lst:\n",
    "    beta_hat = minimize(fun=Lasso, x0=beta0, args=(X_train,y_train)).x\n",
    "    rss = RSS(beta_hat,X_test,y_test)\n",
    "    print(lamda,rss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamda_lst = np.arange(0.001,0.11,0.001)\n",
    "RSS_lst = []\n",
    "for lamda in lamda_lst:\n",
    "    beta_hat = minimize(fun=Lasso, x0=beta0, args=(X_train,y_train)).x\n",
    "    RSS_lst.append(RSS(beta_hat,X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lamda_lst,RSS_lst);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, do you think that the magnitude of the features in X may affect the results with regularization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** Yes, I think the magnitude of the features in X may affect the results with regularization. Suppose we are using lambda = 0.01 and L1 regularization. The resulting RSS is 10079.45, much bigger than the RSS before. While this time since every feature has the same scale, we can say that alcohol is the most important feature since it has largest beta, 0.288."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS with L1 regularization on scaled test set:  10079.456232620083\n"
     ]
    }
   ],
   "source": [
    "X_train_scale = preprocessing.scale(X_train)\n",
    "X_test_scale = preprocessing.scale(X_test)\n",
    "\n",
    "beta0 = np.random.normal(0,1,X_train.shape[1])\n",
    "lamda = 0.01\n",
    "beta_hat_with_L1 = minimize(fun=Lasso, x0=beta0, args=(X_train_scale,y_train)).x\n",
    "print(\"RSS with L1 regularization on scaled test set: \",RSS(beta_hat_with_L1,X_test_scale,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.01420455,  0.08518625, -0.19965283, -0.05462014,  0.02862941,\n",
       "       -0.08415666,  0.055898  , -0.11088721, -0.07042476, -0.05453225,\n",
       "        0.15690765,  0.28803828])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_hat_with_L1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
